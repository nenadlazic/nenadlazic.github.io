<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Ocr on </title>
    <link>https://nenadlazic.github.io/tags/ocr/</link>
    <description>Recent content in Ocr on </description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 05 Feb 2026 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://nenadlazic.github.io/tags/ocr/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Teaching Tesseract to Read Our Data</title>
      <link>https://nenadlazic.github.io/blog/tesseract-fine-tuning-ocr/</link>
      <pubDate>Thu, 05 Feb 2026 00:00:00 +0000</pubDate>
      <guid>https://nenadlazic.github.io/blog/tesseract-fine-tuning-ocr/</guid>
      <description>&lt;p&gt;In practice, getting good OCR results is rarely about a single improvement. It’s a chain of steps and the weakest one usually defines the final accuracy.&lt;/p&gt;&#xA;&lt;p&gt;In one of previous post, &lt;a href=&#34;https://nenadlazic.github.io/blog/better-ocr-with-image-preprocessing/&#34;&gt;Getting better OCR results: Practical image preprocessing tips&lt;/a&gt;, we focused on improving OCR accuracy by cleaning up images, reducing noise, and normalizing contrast. That work is essential, and without it, OCR systems like Tesseract struggle immediately when applied to real-world data.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Getting better OCR results: Practical image preprocessing tips</title>
      <link>https://nenadlazic.github.io/blog/better-ocr-with-image-preprocessing/</link>
      <pubDate>Fri, 31 Oct 2025 00:00:00 +0000</pubDate>
      <guid>https://nenadlazic.github.io/blog/better-ocr-with-image-preprocessing/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;In many modern applications, text doesn’t always arrive as plain, selectable characters. It often  appears inside images like scanned documents, screenshots, ID cards, receipts, or even video subtitles. In these cases, the text looks readable to humans but is invisible to software systems that expect digital text.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;O&lt;/strong&gt;ptical &lt;strong&gt;C&lt;/strong&gt;haracter &lt;strong&gt;R&lt;/strong&gt;ecognition (&lt;strong&gt;OCR&lt;/strong&gt;) helps bridge that gap by detecting and converting text from images into editable and searchable form. This makes it possible to process documents automatically, extract data, enable search, or translate visual text.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
